#!/usr/bin/env python3
"""
ä¸€å°ä¸€å°è©±åŠŸèƒ½æ¸¬è©¦è…³æœ¬
"""

def test_private_conversation_logic():
    """æ¨¡æ“¬ä¸€å°ä¸€å°è©±çš„é‚è¼¯æ¸¬è©¦"""
    
    print("ğŸ” ä¸€å°ä¸€å°è©±é‚è¼¯æ¸¬è©¦")
    print("=" * 50)
    
    # æ¨¡æ“¬ä¸åŒçš„ç§äººè¨Šæ¯å ´æ™¯
    test_cases = [
        {
            "text": "ä½ å¥½",
            "source_type": "user",
            "expected": "ä¸€èˆ¬ AI å°è©±",
            "should_reply": True,
            "is_special_command": False
        },
        {
            "text": "ä»€éº¼æ˜¯ Pythonï¼Ÿ",
            "source_type": "user", 
            "expected": "ä¸€èˆ¬ AI å°è©±",
            "should_reply": True,
            "is_special_command": False
        },
        {
            "text": "!help",
            "source_type": "user",
            "expected": "é¡¯ç¤ºå¹«åŠ©",
            "should_reply": True,
            "is_special_command": True
        },
        {
            "text": "!æ‘˜è¦",
            "source_type": "user",
            "expected": "ç”¢ç”Ÿæ‘˜è¦",
            "should_reply": True,
            "is_special_command": True
        }
    ]
    
    special_commands = ['!æ¸…ç©º', '!æ‘˜è¦', 'ï¼æ¸…ç©º', 'ï¼æ‘˜è¦', '!help', '!å¹«åŠ©', 'ï¼help', 'ï¼å¹«åŠ©']
    
    for i, case in enumerate(test_cases, 1):
        text = case["text"]
        source_type = case["source_type"]
        
        # æ¨¡æ“¬é‚è¼¯åˆ¤æ–·
        should_reply = False
        is_ai_question = False
        
        if source_type == 'group':
            # ç¾¤çµ„é‚è¼¯ï¼ˆé€™è£¡ä¸æ¸¬è©¦ï¼‰
            pass
        else:
            # ç§äººå°è©±ï¼šæ‰€æœ‰è¨Šæ¯éƒ½å›æ‡‰
            should_reply = True
            has_special_command = any(cmd in text.lower() for cmd in special_commands)
        
        # åˆ¤æ–·æœƒé€²å…¥å“ªå€‹è™•ç†åˆ†æ”¯
        if should_reply:
            if text.lower() in ['!æ¸…ç©º', 'ï¼æ¸…ç©º']:
                branch = "æ¸…ç©ºæŒ‡ä»¤"
            elif text.lower() in ['!æ‘˜è¦', 'ï¼æ‘˜è¦']:
                branch = "æ‘˜è¦æŒ‡ä»¤"
            elif text.lower() in ['!help', '!å¹«åŠ©', 'ï¼help', 'ï¼å¹«åŠ©']:
                branch = "å¹«åŠ©æŒ‡ä»¤"
            elif is_ai_question:
                branch = "AI å•ç­”æ¨¡å¼"
            else:
                branch = "ä¸€èˆ¬å°è©±"
        else:
            branch = "ä¸å›æ‡‰"
        
        result = "âœ…" if branch == case["expected"] or (branch == "ä¸€èˆ¬å°è©±" and case["expected"] == "ä¸€èˆ¬ AI å°è©±") else "âŒ"
        
        print(f"{result} æ¸¬è©¦ {i}: '{text}'")
        print(f"   é æœŸ: {case['expected']}")
        print(f"   å¯¦éš›: {branch}")
        print(f"   should_reply: {should_reply}")
        print()

def check_gemini_model():
    """æª¢æŸ¥ Gemini æ¨¡å‹é…ç½®"""
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    
    print("ğŸ”§ ç’°å¢ƒé…ç½®æª¢æŸ¥")
    print("=" * 50)
    
    gemini_key = os.getenv('GEMINI_API_KEY')
    gemini_model = os.getenv('GEMINI_MODEL', 'gemini-2.5-flash')
    
    print(f"GEMINI_API_KEY: {'âœ… å·²è¨­å®š' if gemini_key else 'âŒ æœªè¨­å®š'}")
    print(f"GEMINI_MODEL: {gemini_model}")
    print()

def debug_tips():
    """æä¾›é™¤éŒ¯å»ºè­°"""
    print("ğŸ› é™¤éŒ¯å»ºè­°")
    print("=" * 50)
    print("1. æª¢æŸ¥ LINE Bot æ—¥èªŒï¼Œçœ‹çœ‹æ˜¯å¦æœ‰éŒ¯èª¤è¨Šæ¯")
    print("2. ç¢ºèªç§äººå°è©±çš„ webhook æœ‰æ­£ç¢ºæ¥æ”¶")
    print("3. æª¢æŸ¥ Firebase æ˜¯å¦æ­£å¸¸å„²å­˜è¨Šæ¯")
    print("4. ç¢ºèª Gemini API é‡‘é‘°æ˜¯å¦æœ‰æ•ˆ")
    print("5. æª¢æŸ¥æ˜¯å¦æœ‰ç¶²è·¯é€£ç·šå•é¡Œ")
    print()
    print("ğŸ” æª¢æŸ¥æ–¹å¼ï¼š")
    print("- ç™¼é€ '!help' çœ‹æ˜¯å¦æœ‰å›æ‡‰")
    print("- æŸ¥çœ‹çµ‚ç«¯çš„ log è¼¸å‡º")
    print("- ç¢ºèª webhook URL è¨­å®šæ­£ç¢º")

if __name__ == "__main__":
    test_private_conversation_logic()
    check_gemini_model()
    debug_tips()
