import logging
import os
import sys
import mimetypes
import uuid
import tempfile
import asyncio
import time
from datetime import datetime
if os.getenv('API_ENV') != 'production':
    from dotenv import load_dotenv

    load_dotenv()


from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import PlainTextResponse
from linebot.v3.webhook import WebhookParser
from linebot.v3.messaging import (
    AsyncApiClient,
    AsyncMessagingApi,
    AsyncMessagingApiBlob,
    Configuration,
    ReplyMessageRequest,
    PushMessageRequest,
    ImageMessage)
from linebot.v3.exceptions import (
    InvalidSignatureError
)
from linebot.v3.webhooks import (
    MessageEvent,
    TextMessageContent,
    AudioMessageContent,
    FileMessageContent
)
import google.generativeai as genai
from google import genai as genai_v2
from google.genai import types
from google.cloud import storage
import uvicorn
from firebase import firebase
from flex_msg import create_flex_message
from asr import ASRHandler
import drive_export

logging.basicConfig(
    level=os.getenv('LOG', 'INFO'),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__file__)

app = FastAPI()

# Initialize ASR Handler
asr_handler = ASRHandler()

channel_secret = os.getenv('LINE_CHANNEL_SECRET', None)
channel_access_token = os.getenv('LINE_CHANNEL_ACCESS_TOKEN', None)
if channel_secret is None:
    print('Specify LINE_CHANNEL_SECRET as environment variable.')
    sys.exit(1)
if channel_access_token is None:
    print('Specify LINE_CHANNEL_ACCESS_TOKEN as environment variable.')
    sys.exit(1)

configuration = Configuration(
    access_token=channel_access_token
)

parser = WebhookParser(channel_secret)


firebase_url = os.getenv('FIREBASE_URL')

# Gemini LLM è¨­å®šï¼ˆæ–‡å­—å°è©±ã€æ‘˜è¦ç­‰ï¼‰
gemini_llm_key = os.getenv('GEMINI_LLM_API_KEY')
gemini_llm_model = os.getenv('GEMINI_LLM_MODEL', 'gemini-flash-latest')

# Gemini Image è¨­å®šï¼ˆåœ–ç‰‡ç”Ÿæˆï¼‰
gemini_image_key = os.getenv('GEMINI_IMAGE_API_KEY')
gemini_image_model = os.getenv('GEMINI_IMAGE_MODEL', 'gemini-3-pro-image-preview')

# ç‚ºäº†å‘å¾Œç›¸å®¹ï¼Œå¦‚æœæ²’æœ‰è¨­å®šåˆ†é›¢çš„ keyï¼Œå°±ä½¿ç”¨èˆŠçš„è¨­å®š
if not gemini_llm_key:
    gemini_llm_key = os.getenv('GEMINI_API_KEY')
if not gemini_image_key:
    gemini_image_key = os.getenv('GEMINI_API_KEY')
if not gemini_llm_model and os.getenv('GEMINI_MODEL'):
    gemini_llm_model = os.getenv('GEMINI_MODEL')

bot_line_id = os.getenv('LINE_BOT_ID', '377mwhqu')  # Bot çš„ LINE ID

# Google Cloud Storage è¨­å®š
gcs_bucket_name = os.getenv('GCS_BUCKET_NAME')  # ä½ çš„ Google Cloud Storage bucket åç¨±
gcs_credentials_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')  # Google Cloud èªè­‰æª”æ¡ˆè·¯å¾‘


# Initialize the Gemini LLM API
genai.configure(api_key=gemini_llm_key)

# Initialize Google Cloud Storage client
if gcs_credentials_path and gcs_bucket_name:
    try:
        logging.info("Initializing Google Cloud Storage...")
        logging.info(f"GCS bucket name: {gcs_bucket_name}")
        logging.info(f"GCS credentials path: {gcs_credentials_path}")
        
        storage_client = storage.Client()
        bucket = storage_client.bucket(gcs_bucket_name)
        
        # æ¸¬è©¦ bucket æ˜¯å¦å­˜åœ¨
        if bucket.exists():
            logging.info(f"Successfully connected to GCS bucket: {gcs_bucket_name}")
        else:
            logging.error(f"GCS bucket does not exist: {gcs_bucket_name}")
            bucket = None
            
    except Exception as e:
        logging.error(f"Failed to initialize Google Cloud Storage: {e}")
        storage_client = None
        bucket = None
else:
    logging.warning("Google Cloud Storage not configured. Image generation will be disabled.")
    logging.warning(f"GCS_BUCKET_NAME: {gcs_bucket_name}")
    logging.warning(f"GOOGLE_APPLICATION_CREDENTIALS: {gcs_credentials_path}")
    storage_client = None
    bucket = None


async def upload_image_to_gcs(image_data, filename, mime_type="image/png"):
    """
    ä¸Šå‚³åœ–ç‰‡åˆ° Google Cloud Storage ä¸¦è¿”å›å…¬é–‹ URL
    
    Args:
        image_data: åœ–ç‰‡çš„äºŒé€²ä½è³‡æ–™
        filename: æª”æ¡ˆåç¨±
        mime_type: åœ–ç‰‡çš„ MIME é¡å‹ï¼Œé è¨­ç‚º image/png
    
    Returns:
        str: åœ–ç‰‡çš„å…¬é–‹ URLï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å› None
    """
    logging.info(f"Starting upload_image_to_gcs - filename: {filename}")
    logging.info(f"Image data type: {type(image_data)}, size: {len(image_data) if image_data else 'None'}")
    
    if not bucket:
        logging.error("Google Cloud Storage not configured - bucket is None")
        logging.error(f"GCS bucket name: {gcs_bucket_name}")
        logging.error(f"GCS credentials path: {gcs_credentials_path}")
        return None
    
    try:
        # å»ºç«‹å”¯ä¸€çš„æª”æ¡ˆåç¨± (ç¢ºä¿æ²’æœ‰ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        # é€²ä¸€æ­¥æ¸…ç†æª”æ¡ˆåç¨±ï¼Œç¢ºä¿åªåŒ…å«å®‰å…¨å­—ç¬¦
        safe_filename = "".join(c if c.isalnum() or c in ('-', '_', '.') else '_' for c in filename)
        unique_filename = f"linebot_images/{timestamp}_{safe_filename}"
        logging.info(f"Generated unique filename: {unique_filename}")
        
        # ä¸Šå‚³åˆ° GCS
        logging.info(f"Creating blob in bucket: {bucket.name}")
        blob = bucket.blob(unique_filename)
        
        logging.info("Starting upload to GCS...")
        # è¨­å®šæ­£ç¢ºçš„ content_type ä»¥ç¢ºä¿åœ–ç‰‡èƒ½æ­£ç¢ºé¡¯ç¤º
        blob.upload_from_string(image_data, content_type=mime_type)
        logging.info(f"Upload completed successfully with content_type: {mime_type}")
        
        # å°æ–¼å•Ÿç”¨äº† uniform bucket-level access çš„ bucketï¼Œ
        # æˆ‘å€‘ä¸éœ€è¦å‘¼å« make_public()ï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨å…¬é–‹ URL
        logging.info("Generating public URL (uniform bucket-level access enabled)...")
        
        # ç›´æ¥æ§‹å»ºå…¬é–‹ URLï¼Œç¢ºä¿æ­£ç¢ºç·¨ç¢¼
        from urllib.parse import quote
        encoded_filename = quote(unique_filename, safe='/')
        public_url = f"https://storage.googleapis.com/{bucket.name}/{encoded_filename}"
        logging.info(f"Image uploaded successfully: {public_url}")
        logging.info(f"Blob exists: {blob.exists()}")
        return public_url
        
    except Exception as e:
        logging.error(f"Failed to upload image to GCS: {e}")
        logging.error(f"Exception type: {type(e)}")
        import traceback
        logging.error(f"Traceback: {traceback.format_exc()}")
        return None


async def generate_image_with_gemini(prompt, max_retries=1, retry_delay=15):
    """
    ä½¿ç”¨ Gemini ç”Ÿæˆåœ–ç‰‡
    
    Args:
        prompt: åœ–ç‰‡ç”Ÿæˆçš„æç¤ºè©
        max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸
        retry_delay: é‡è©¦å»¶é²ï¼ˆç§’ï¼‰
    
    Returns:
        tuple: (æˆåŠŸç‹€æ…‹, çµæœè¨Šæ¯æˆ–åœ–ç‰‡URL)
    """
    logging.info(f"Starting generate_image_with_gemini with prompt: {prompt}")
    
    # æª¢æŸ¥åœ–ç‰‡ç”Ÿæˆ API è¨­å®š
    if not gemini_image_key:
        logging.error("Gemini Image API key not configured")
        return False, "åœ–ç‰‡ç”ŸæˆåŠŸèƒ½æœªè¨­å®š API Key"
    
    for attempt in range(max_retries + 1):
        if attempt > 0:
            logging.info(f"Retry attempt {attempt}/{max_retries} after {retry_delay} seconds...")
            await asyncio.sleep(retry_delay)
        
        try:
            logging.info(f"Creating Gemini Image client with API key: {gemini_image_key[:10]}...{gemini_image_key[-5:] if gemini_image_key else 'None'}")
            client = genai_v2.Client(api_key=gemini_image_key)
            
            # ä½¿ç”¨ç’°å¢ƒè®Šæ•¸è¨­å®šçš„æ¨¡å‹
            model = gemini_image_model
            logging.info(f"Using image model: {model} (attempt {attempt + 1})")
            
            # ä½¿ç”¨ç°¡å–®ç›´æ¥çš„æç¤ºè©ï¼Œæ¸¬è©¦è­‰å¯¦æœ‰æ•ˆ
            prompts_to_try = [
                f"Create a photorealistic image of a {prompt}. Do not provide text description, only generate the actual image.",
                f"Generate image: {prompt}",
                f"Draw: {prompt}"
            ]
            
            current_prompt = prompts_to_try[min(attempt, len(prompts_to_try) - 1)]
            logging.info(f"Using prompt strategy {attempt + 1}: {current_prompt[:80]}...")
            
            # ä½¿ç”¨ç°¡å–®çš„å…§å®¹çµæ§‹ï¼Œèˆ‡æ¸¬è©¦ä¸­æˆåŠŸçš„ç›¸åŒ
            contents = [
                types.Content(
                    role="user",
                    parts=[
                        types.Part.from_text(text=current_prompt),
                    ],
                ),
            ]
            
            generate_content_config = types.GenerateContentConfig(
                response_modalities=["IMAGE", "TEXT"],
            )
            
            logging.info("Starting content generation stream...")
            
            # ç”Ÿæˆå…§å®¹
            image_url = None
            text_response = ""
            chunk_count = 0
            
            for chunk in client.models.generate_content_stream(
                model=model,
                contents=contents,
                config=generate_content_config,
            ):
                chunk_count += 1
                logging.info(f"Processing chunk {chunk_count}")
                
                # æª¢æŸ¥ chunk æ˜¯å¦æœ‰æœ‰æ•ˆçš„ candidates
                if (
                    not hasattr(chunk, 'candidates') or
                    chunk.candidates is None or
                    len(chunk.candidates) == 0 or
                    chunk.candidates[0].content is None or
                    chunk.candidates[0].content.parts is None or
                    len(chunk.candidates[0].content.parts) == 0
                ):
                    logging.warning(f"Chunk {chunk_count} has no valid content")
                    continue
                    
                part = chunk.candidates[0].content.parts[0]
                logging.info(f"Chunk {chunk_count} part type: {type(part)}")
                
                # æª¢æŸ¥æ˜¯å¦æœ‰ inline_data
                if hasattr(part, 'inline_data') and part.inline_data:
                    logging.info(f"Found inline_data in chunk {chunk_count}: {type(part.inline_data)}")
                    if hasattr(part.inline_data, 'data') and part.inline_data.data:
                        logging.info(f"Found image data in chunk {chunk_count}")
                        inline_data = part.inline_data
                        image_data = inline_data.data
                        logging.info(f"Image data size: {len(image_data)} bytes")
                        logging.info(f"Image MIME type: {inline_data.mime_type}")
                        
                        file_extension = mimetypes.guess_extension(inline_data.mime_type) or '.png'
                        logging.info(f"File extension: {file_extension}")
                        
                        # å»ºç«‹æª”æ¡ˆåç¨± (ç§»é™¤ç©ºæ ¼ï¼Œä½¿ç”¨åº•ç·šæ›¿ä»£)
                        safe_prompt = "".join(c if c.isalnum() or c in ('-', '_') else '_' for c in prompt).rstrip()[:30]
                        filename = f"gemini_image_{safe_prompt}{file_extension}"
                        logging.info(f"Generated filename: {filename}")
                        
                        # ä¸Šå‚³åˆ° Google Cloud Storage
                        logging.info("Starting upload to GCS...")
                        image_url = await upload_image_to_gcs(image_data, filename, inline_data.mime_type)
                        logging.info(f"Upload result: {image_url}")
                        
                        # ä¸€æ—¦æ‰¾åˆ°åœ–ç‰‡å°±è·³å‡ºè¿´åœˆ
                        if image_url:
                            logging.info("Image found and uploaded successfully, breaking loop")
                            break
                    else:
                        logging.info(f"inline_data exists but no data: {part.inline_data}")
                else:
                    logging.info(f"No inline_data in chunk {chunk_count}")
                
                # è™•ç†æ–‡å­—å›æ‡‰
                if hasattr(part, 'text') and part.text:
                    text_response += part.text
                    logging.info(f"Received text in chunk {chunk_count}: {part.text[:100]}...")
                elif hasattr(chunk, 'text') and chunk.text:
                    text_response += chunk.text
                    logging.info(f"Received text from chunk object in chunk {chunk_count}: {chunk.text[:100]}...")
                else:
                    logging.info(f"Chunk {chunk_count} has no text data")
            
            logging.info(f"Finished processing {chunk_count} chunks")
            logging.info(f"Final image_url: {image_url}")
            logging.info(f"Final text_response: {text_response[:200]}...")
            
            if image_url:
                logging.info("Image generation successful")
                return True, image_url
            else:
                if text_response:
                    logging.warning(f"Model returned text only, no image generated. Text: {text_response[:200]}")
                    return False, "âŒ æ¨¡å‹åªè¿”å›æ–‡å­—èªªæ˜è€Œæœªç”Ÿæˆåœ–ç‰‡ã€‚è«‹å˜—è©¦æ›´å…·é«”çš„æè¿°ï¼Œä¾‹å¦‚ï¼š'ä¸€ä½å°ç£å©¦å¥³åœ¨å‚³çµ±å¸‚å ´æŒ‘é¸æ–°é®®è”¬èœçš„çœŸå¯¦ç…§ç‰‡'"
                else:
                    return False, "âŒ åœ–ç‰‡ç”Ÿæˆå¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
                
        except Exception as e:
            logging.error(f"Error generating image with Gemini (attempt {attempt + 1}): {e}")
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºé…é¡éŒ¯èª¤
            error_msg = str(e)
            is_quota_error = "429" in error_msg and "RESOURCE_EXHAUSTED" in error_msg
            is_rate_limit = "429" in error_msg
            
            if attempt < max_retries and is_rate_limit:
                logging.info(f"Rate limit hit, will retry in {retry_delay} seconds...")
                continue
            else:
                # æœ€å¾Œä¸€æ¬¡å˜—è©¦æˆ–éé‡è©¦éŒ¯èª¤
                if is_quota_error:
                    return False, "âŒ åœ–ç‰‡ç”Ÿæˆé…é¡å·²ç”¨ç›¡ï¼Œè«‹ç¨å¾Œå†è©¦æˆ–å‡ç´šè‡³ä»˜è²»æ–¹æ¡ˆã€‚"
                elif "quota" in error_msg.lower():
                    return False, "âŒ API é…é¡ä¸è¶³ï¼Œè«‹æª¢æŸ¥æ‚¨çš„ Google AI ä½¿ç”¨é¡åº¦ã€‚"
                else:
                    return False, "âŒ ç”Ÿæˆåœ–ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
    
    return False, "âŒ ç¶“éå¤šæ¬¡é‡è©¦ä»ç„¡æ³•ç”Ÿæˆåœ–ç‰‡ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"


def is_bot_mentioned(event, bot_id=None, text=None):
    """
    æª¢æŸ¥æ˜¯å¦ Bot è¢«æåŠ
    
    Args:
        event: LINE webhook event
        bot_id: Bot çš„ LINE IDï¼ˆå¯é¸ï¼‰
        text: è¨Šæ¯æ–‡å­—ï¼ˆå¯é¸ï¼Œè‹¥ç‚º None å‰‡å˜—è©¦å¾ event.message ç²å–ï¼‰
    
    Returns:
        bool: True å¦‚æœ Bot è¢«æåŠï¼ŒFalse å¦å‰‡
    """
    if text is None:
        if not isinstance(event.message, TextMessageContent):
            return False
        text = event.message.text
    
    mention = getattr(event.message, 'mention', None)
    
    # æ–¹æ³•1: æª¢æŸ¥ mention ç‰©ä»¶ä¸­æ˜¯å¦åŒ…å«ç‰¹å®šçš„ç”¨æˆ¶ID
    if mention and hasattr(mention, 'mentionees'):
        # æ³¨æ„ï¼šé€™éœ€è¦çŸ¥é“ Bot çš„å¯¦éš› user_idï¼Œé€šå¸¸æ ¼å¼ç‚º Ué–‹é ­
        # ä½†æˆ‘å€‘å¯èƒ½ç„¡æ³•ç›´æ¥ç²å–åˆ° Bot è‡ªå·±çš„ user_id
        pass
    
    # æ–¹æ³•2: æª¢æŸ¥æ–‡å­—ä¸­æ˜¯å¦åŒ…å« Bot çš„å®˜æ–¹ ID
    if bot_id:
        # æª¢æŸ¥æ˜¯å¦åŒ…å« @bot_id æ ¼å¼ï¼ˆç¢ºä¿ @ å‰é¢æ²’æœ‰å…¶ä»–å­—ç¬¦ï¼‰
        import re
        bot_patterns = [
            rf'(?<![a-zA-Z0-9])@{re.escape(bot_id)}(?![a-zA-Z0-9])',
            rf'(?<![a-zA-Z0-9])ï¼ {re.escape(bot_id)}(?![a-zA-Z0-9])',
            rf'(?<![a-zA-Z0-9])@{re.escape(bot_id.lower())}(?![a-zA-Z0-9])',
            rf'(?<![a-zA-Z0-9])ï¼ {re.escape(bot_id.lower())}(?![a-zA-Z0-9])'
        ]
        
        for pattern in bot_patterns:
            if re.search(pattern, text):
                logging.info(f"Bot mentioned with pattern: {pattern}")
                return True
    
    # æ–¹æ³•3: æª¢æŸ¥æ˜¯å¦æœ‰ mention ä¸”æ–‡å­—åŒ…å«é—œéµè©
    if mention:
        # æª¢æŸ¥å¸¸è¦‹çš„ Bot å‘¼å«æ–¹å¼
        bot_keywords = ['bot', 'Bot', 'BOT', 'æ©Ÿå™¨äºº', 'æ‘˜è¦ç‹']
        if any(keyword in text for keyword in bot_keywords):
            logging.info(f"Bot mentioned with keyword in text: {text}")
            return True
    
    return False


@app.get("/health")
async def health():
    return 'ok'

@app.get("/")
async def root():
    return {"message": "LINE Bot is running", "status": "ok"}


@app.get("/auth/google/callback")
async def google_oauth_callback(request: Request):
    code = request.query_params.get("code")
    state = request.query_params.get("state")
    error = request.query_params.get("error")

    if error:
        return PlainTextResponse(f"OAuth failed: {error}", status_code=400)
    if not code or not state:
        return PlainTextResponse("Missing code/state", status_code=400)

    try:
        payload = drive_export.verify_state(state)
    except Exception as e:
        logging.error(f"OAuth state verification failed: {e}")
        return PlainTextResponse("Invalid state", status_code=400)

    group_id = payload.get("group_id")
    line_user_id = payload.get("line_user_id")
    bind_code = payload.get("bind_code")
    nonce = payload.get("nonce")

    if not group_id or not line_user_id or not bind_code or not nonce:
        return PlainTextResponse("Invalid state payload", status_code=400)

    client_id = os.getenv("GOOGLE_OAUTH_CLIENT_ID")
    client_secret = os.getenv("GOOGLE_OAUTH_CLIENT_SECRET")
    redirect_base = os.getenv("OAUTH_REDIRECT_BASE")
    if not client_id or not client_secret or not redirect_base:
        logging.error("Google OAuth env vars missing")
        return PlainTextResponse("Server not configured for Google OAuth", status_code=500)

    redirect_uri = redirect_base.rstrip("/") + "/auth/google/callback"

    fdb = firebase.FirebaseApplication(firebase_url, None)

    code_record = fdb.get('drive_bind_codes', bind_code)
    if not isinstance(code_record, dict):
        return PlainTextResponse("Bind code not found", status_code=400)

    expires_at = code_record.get("expires_at")
    if not isinstance(expires_at, int) or int(time.time()) > expires_at:
        return PlainTextResponse("Bind code expired", status_code=400)

    if code_record.get("used_at"):
        return PlainTextResponse("Bind code already used", status_code=400)

    if code_record.get("group_id") != group_id:
        return PlainTextResponse("Bind code group mismatch", status_code=400)

    if code_record.get("requested_by_line_user_id") != line_user_id:
        return PlainTextResponse("Bind code user mismatch", status_code=400)

    if code_record.get("oauth_nonce") != nonce:
        return PlainTextResponse("Bind code nonce mismatch", status_code=400)

    try:
        tokens = drive_export.exchange_code_for_tokens(
            client_id=client_id,
            client_secret=client_secret,
            redirect_uri=redirect_uri,
            code=code,
        )
    except Exception as e:
        logging.error(f"OAuth token exchange failed: {e}")
        return PlainTextResponse("Token exchange failed", status_code=500)

    if not tokens.refresh_token:
        # Do not mark used. User needs to re-consent to obtain refresh token.
        logging.error("No refresh_token returned by Google")
        return PlainTextResponse(
            "No refresh token returned. Please revoke app access in your Google account and relink.",
            status_code=400,
        )

    try:
        refresh_token_enc = drive_export.encrypt_refresh_token(tokens.refresh_token)
    except Exception as e:
        logging.error(f"Failed to encrypt refresh token: {e}")
        return PlainTextResponse("Server encryption error", status_code=500)

    try:
        folder_name = f"LINE Bot Export - {group_id}"
        folder_id, folder_name = drive_export.drive_ensure_folder(
            access_token=tokens.access_token,
            name=folder_name,
            parent_id=None,
        )
    except Exception as e:
        logging.error(f"Drive folder creation failed: {e}")
        return PlainTextResponse("Drive folder creation failed", status_code=500)

    drive_export_cfg = {
        "enabled": True,
        "owner_line_user_id": line_user_id,
        "owner_claimed_at": int(time.time()),
        "google": {
            "refresh_token_enc": refresh_token_enc,
            "token_created_at": int(time.time()),
            "scopes": (tokens.scope or "").split(),
        },
        "drive": {
            "folder_id": folder_id,
            "folder_name": folder_name,
        },
    }

    try:
        fdb.put(f'groups/{group_id}/info', 'drive_export', drive_export_cfg)
        code_record["used_at"] = int(time.time())
        fdb.put('drive_bind_codes', bind_code, code_record)
    except Exception as e:
        logging.error(f"Failed to persist drive export config: {e}")
        return PlainTextResponse("Failed to save configuration", status_code=500)

    async_api_client = AsyncApiClient(configuration)
    line_bot_api = AsyncMessagingApi(async_api_client)
    try:
        await line_bot_api.push_message(
            PushMessageRequest(
                to=line_user_id,
                messages=[create_flex_message("âœ… å·²å•Ÿç”¨ Google Drive è½‰å­˜ï¼ˆæ­¤ç¾¤çµ„ï¼‰", title="Drive è½‰å­˜")],
            )
        )
    except Exception as e:
        logging.error(f"Failed to push confirmation message: {e}")
    finally:
        await async_api_client.close()

    return PlainTextResponse("Drive export enabled. You can close this page.")


@app.post("/webhooks/line")
async def handle_callback(request: Request):
    signature = request.headers['X-Line-Signature']

    # get request body as text
    body = await request.body()
    body = body.decode()

    try:
        events = parser.parse(body, signature)
    except InvalidSignatureError:
        raise HTTPException(status_code=400, detail="Invalid signature")

    # å‰µå»º async client åœ¨ async å‡½æ•¸å…§
    async_api_client = AsyncApiClient(configuration)
    line_bot_api = AsyncMessagingApi(async_api_client)
    line_bot_api_blob = AsyncMessagingApiBlob(async_api_client)
    
    try:
        for event in events:
            logging.info(event)
            if not isinstance(event, MessageEvent):
                continue
            
            user_id = event.source.user_id
            text = ""
            
            if isinstance(event.message, TextMessageContent):
                text = event.message.text
            elif isinstance(event.message, AudioMessageContent):
                # Handle Audio
                try:
                    message_id = event.message.id
                    # Get message content using AsyncMessagingApiBlob
                    message_content_response = await line_bot_api_blob.get_message_content(message_id)
                    
                    # Save to temp file
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.m4a') as tf:
                        # The response is a stream, read the content
                        tf.write(message_content_response)
                        temp_file_path = tf.name
                    
                    logging.info(f"Transcribing audio: {temp_file_path}")
                    text = asr_handler.transcribe(temp_file_path)
                    logging.info(f"Transcribed text: {text}")
                    
                    # Clean up
                    os.unlink(temp_file_path)
                    
                    if not text:
                        continue
                        
                except Exception as e:
                    logging.error(f"Error handling audio message: {e}")
                    continue
            else:
                if isinstance(event.message, FileMessageContent):
                    if event.source.type != 'group':
                        continue

                    group_id = event.source.group_id
                    message_id = event.message.id
                    file_name = drive_export.safe_filename(
                        getattr(event.message, 'file_name', '') or getattr(event.message, 'fileName', ''),
                        fallback=f"line_file_{message_id}",
                    )
                    file_size = getattr(event.message, 'file_size', None)

                    # Simple size guard (avoid extremely large uploads).
                    if isinstance(file_size, int) and file_size > 50 * 1024 * 1024:
                        logging.warning(f"File too large for Drive export: {file_size} bytes")
                        continue

                    fdb = firebase.FirebaseApplication(firebase_url, None)
                    try:
                        cfg = fdb.get(f'groups/{group_id}/info', 'drive_export')
                    except Exception as e:
                        logging.error(f"Failed to read drive_export config: {e}")
                        continue

                    if not isinstance(cfg, dict) or not cfg.get('enabled'):
                        continue

                    uploads_path = f'groups/{group_id}/info/drive_export/uploads'
                    try:
                        existing = fdb.get(uploads_path, message_id)
                    except Exception:
                        existing = None

                    if isinstance(existing, dict) and existing.get('status') in ('pending', 'success'):
                        continue

                    try:
                        fdb.put(uploads_path, message_id, {
                            'status': 'pending',
                            'created_at': int(time.time()),
                        })
                    except Exception as e:
                        logging.error(f"Failed to create upload record: {e}")
                        continue

                    try:
                        message_content = await line_bot_api_blob.get_message_content(message_id)
                    except Exception as e:
                        logging.error(f"Failed to download LINE file content: {e}")
                        try:
                            fdb.put(uploads_path, message_id, {
                                'status': 'failed',
                                'error': 'line_download_failed',
                                'created_at': int(time.time()),
                            })
                        except Exception:
                            pass
                        continue

                    with tempfile.NamedTemporaryFile(delete=False) as tf:
                        tf.write(message_content)
                        temp_file_path = tf.name

                    try:
                        google_cfg = cfg.get('google', {}) if isinstance(cfg.get('google'), dict) else {}
                        drive_cfg = cfg.get('drive', {}) if isinstance(cfg.get('drive'), dict) else {}
                        refresh_token_enc = google_cfg.get('refresh_token_enc')
                        folder_id = drive_cfg.get('folder_id')

                        if not refresh_token_enc or not folder_id:
                            raise RuntimeError('drive_export_not_configured')

                        client_id = os.getenv('GOOGLE_OAUTH_CLIENT_ID')
                        client_secret = os.getenv('GOOGLE_OAUTH_CLIENT_SECRET')
                        if not client_id or not client_secret:
                            raise RuntimeError('google_oauth_env_missing')

                        def do_upload() -> str:
                            refresh_token = drive_export.decrypt_refresh_token(refresh_token_enc)
                            access_token = drive_export.refresh_access_token(
                                client_id=client_id,
                                client_secret=client_secret,
                                refresh_token=refresh_token,
                            )
                            return drive_export.drive_resumable_upload(
                                access_token=access_token,
                                file_path=temp_file_path,
                                filename=file_name,
                                folder_id=folder_id,
                            )

                        drive_file_id = await asyncio.to_thread(do_upload)

                        fdb.put(uploads_path, message_id, {
                            'status': 'success',
                            'drive_file_id': drive_file_id,
                            'created_at': int(time.time()),
                        })
                    except Exception as e:
                        logging.error(f"Drive upload failed: {e}")
                        try:
                            fdb.put(uploads_path, message_id, {
                                'status': 'failed',
                                'error': str(e)[:200],
                                'created_at': int(time.time()),
                            })
                        except Exception:
                            pass
                    finally:
                        try:
                            os.unlink(temp_file_path)
                        except Exception:
                            pass

                    continue

                continue

            fdb = firebase.FirebaseApplication(firebase_url, None)
            
            # è¨­å®š Firebase è·¯å¾‘
            if event.source.type == 'group':
                user_chat_path = f'groups/{event.source.group_id}'
            else:
                user_chat_path = f'users/{user_id}'
            
            # æ±ºå®šæ˜¯å¦è¦å›æ‡‰
            should_reply = False
            is_ai_question = False  # æ˜¯å¦ç‚º AI å•ç­”æ¨¡å¼
            is_drive_command = False
            special_commands = ['!æ¸…ç©º', '!clean',  '!æ‘˜è¦','!ç¸½çµ','!summary', 'ï¼æ¸…ç©º', 'ï¼æ‘˜è¦', '!help', '!å¹«åŠ©', 'ï¼help', 'ï¼å¹«åŠ©', '!ç•«åœ–', '!ç”Ÿæˆåœ–ç‰‡', 'ï¼ç•«åœ–', 'ï¼ç”Ÿæˆåœ–ç‰‡', '!image', '!draw', '!drive', 'ï¼drive']
            
            if event.source.type == 'group':
                # æª¢æŸ¥æ˜¯å¦çœŸçš„æåŠäº† Bot
                bot_mentioned = is_bot_mentioned(event, bot_line_id, text=text)
                
                # æª¢æŸ¥æ˜¯å¦åŒ…å«ç‰¹æ®ŠæŒ‡ä»¤
                has_special_command = any(cmd in text.lower() for cmd in special_commands)
                
                if bot_mentioned and not has_special_command:
                    # Bot è¢«æåŠä½†ä¸æ˜¯ç‰¹æ®ŠæŒ‡ä»¤ = AI å•ç­”æ¨¡å¼
                    should_reply = True
                    is_ai_question = True
                    logging.info(f"Bot mentioned - AI question mode: '{text}'")
                elif has_special_command:
                    # ç‰¹æ®ŠæŒ‡ä»¤
                    should_reply = True
                    logging.info(f"Group message with special command: '{text}'")
                else:
                    logging.info(f"Recording group message (no reply): '{text}'")
            else:
                # ç§äººå°è©±ï¼šæ‰€æœ‰è¨Šæ¯éƒ½å›æ‡‰
                should_reply = True
                # æª¢æŸ¥æ˜¯å¦ç‚ºç‰¹æ®ŠæŒ‡ä»¤
                has_special_command = any(cmd in text.lower() for cmd in special_commands)
                if not has_special_command:
                    # ä¸€èˆ¬å°è©±æ¨¡å¼
                    logging.info(f"Private conversation mode: '{text}'")
                else:
                    logging.info(f"Private message with special command: '{text}'")
            
            # ç²å–ç¾æœ‰å°è©±è¨˜éŒ„
            try:
                chatgpt = fdb.get(user_chat_path, 'messages')
                if chatgpt is None:
                    messages = []
                else:
                    messages = chatgpt if isinstance(chatgpt, list) else []
            except Exception as e:
                logging.warning(f"Failed to get messages from Firebase: {e}")
                messages = []

            if text:
                # æ‰€æœ‰è¨Šæ¯éƒ½è¨˜éŒ„åˆ° Firebase
                messages.append({'role': 'user', 'parts': [text], 'timestamp': str(event.timestamp)})
                
                reply_msg = ""
                
                # åªæœ‰åœ¨éœ€è¦å›æ‡‰æ™‚æ‰è™•ç†
                if should_reply:
                    normalized = text.strip().replace('ï¼', '!')
                    lowered = normalized.lower()

                    if lowered.startswith('!drive'):
                        is_drive_command = True
                        tokens = normalized.split()

                        # Ensure drive commands do not pollute conversation history
                        messages.pop()

                        if event.source.type == 'group':
                            group_id = event.source.group_id

                            if len(tokens) < 2:
                                reply_msg = "ç”¨æ³•ï¼š!drive bind | !drive status | !drive off"
                            else:
                                subcmd = tokens[1].lower()
                                if subcmd == 'bind':
                                    try:
                                        existing = fdb.get(f'groups/{group_id}/info', 'drive_export')
                                    except Exception:
                                        existing = None

                                    if isinstance(existing, dict) and existing.get('owner_line_user_id'):
                                        reply_msg = "æ­¤ç¾¤çµ„å·²æœ‰äººç¶å®š Driveã€‚è«‹ç”¨ !drive status æŸ¥çœ‹ï¼Œæˆ–è«‹ owner åŸ·è¡Œ !drive off å¾Œå†é‡æ–°ç¶å®šã€‚"
                                    else:
                                        bind_code = drive_export.generate_bind_code()
                                        expires_at = int(time.time()) + 10 * 60
                                        record = {
                                            'group_id': group_id,
                                            'requested_by_line_user_id': user_id,
                                            'expires_at': expires_at,
                                        }
                                        try:
                                            fdb.put('drive_bind_codes', bind_code, record)
                                            fdb.put(f'groups/{group_id}/info/drive_export', 'bind', {
                                                'active_code': bind_code,
                                                'expires_at': expires_at,
                                                'requested_by_line_user_id': user_id,
                                            })
                                            reply_msg = (
                                                "è«‹ç§è¨Šæˆ‘ä»¥ä¸‹æŒ‡ä»¤å®Œæˆç¶å®šï¼ˆ10 åˆ†é˜å…§æœ‰æ•ˆï¼‰ï¼š\n"
                                                f"!drive link {bind_code}"
                                            )
                                        except Exception as e:
                                            logging.error(f"Failed to create bind code: {e}")
                                            reply_msg = "å»ºç«‹ç¶å®šç¢¼å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

                                elif subcmd == 'status':
                                    try:
                                        cfg = fdb.get(f'groups/{group_id}/info', 'drive_export')
                                    except Exception:
                                        cfg = None

                                    if not isinstance(cfg, dict) or not cfg.get('enabled'):
                                        owner = cfg.get('owner_line_user_id') if isinstance(cfg, dict) else None
                                        bind = cfg.get('bind') if isinstance(cfg, dict) else None
                                        msg = "Drive è½‰å­˜ï¼šæœªå•Ÿç”¨"
                                        if owner:
                                            msg += f"\nOwner: {owner}"
                                        if isinstance(bind, dict) and bind.get('active_code'):
                                            msg += f"\nç¶å®šç¢¼ï¼š{bind.get('active_code')}ï¼ˆåˆ°æœŸï¼š{bind.get('expires_at')}ï¼‰"
                                        reply_msg = msg
                                    else:
                                        drive_cfg = cfg.get('drive', {}) if isinstance(cfg.get('drive'), dict) else {}
                                        reply_msg = (
                                            "Drive è½‰å­˜ï¼šå·²å•Ÿç”¨\n"
                                            f"Owner: {cfg.get('owner_line_user_id')}\n"
                                            f"Folder ID: {drive_cfg.get('folder_id')}"
                                        )

                                elif subcmd == 'off':
                                    try:
                                        cfg = fdb.get(f'groups/{group_id}/info', 'drive_export')
                                    except Exception:
                                        cfg = None

                                    if not isinstance(cfg, dict) or not cfg.get('owner_line_user_id'):
                                        reply_msg = "æ­¤ç¾¤çµ„å°šæœªå•Ÿç”¨ Drive è½‰å­˜ã€‚"
                                    elif cfg.get('owner_line_user_id') != user_id:
                                        reply_msg = "åªæœ‰ owner å¯ä»¥é—œé–‰ Drive è½‰å­˜ã€‚"
                                    else:
                                        try:
                                            fdb.delete(f'groups/{group_id}/info', 'drive_export')
                                            reply_msg = "å·²é—œé–‰ Drive è½‰å­˜ï¼Œç¾¤çµ„å·²å¯é‡æ–°ç¶å®šã€‚"
                                        except Exception as e:
                                            logging.error(f"Failed to disable drive export: {e}")
                                            reply_msg = "é—œé–‰å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

                                else:
                                    reply_msg = "ç”¨æ³•ï¼š!drive bind | !drive status | !drive off"

                        else:
                            # Private chat
                            if len(tokens) < 3:
                                reply_msg = "ç”¨æ³•ï¼š!drive link <BIND_CODE>"
                            else:
                                subcmd = tokens[1].lower()
                                if subcmd != 'link':
                                    reply_msg = "ç”¨æ³•ï¼š!drive link <BIND_CODE>"
                                else:
                                    bind_code = tokens[2].strip()
                                    code_record = fdb.get('drive_bind_codes', bind_code)
                                    if not isinstance(code_record, dict):
                                        reply_msg = "ç¶å®šç¢¼ä¸å­˜åœ¨ã€‚"
                                    else:
                                        expires_at = code_record.get('expires_at')
                                        if not isinstance(expires_at, int) or int(time.time()) > expires_at:
                                            reply_msg = "ç¶å®šç¢¼å·²éæœŸï¼Œè«‹å›ç¾¤çµ„é‡æ–°åŸ·è¡Œ !drive bindã€‚"
                                        elif code_record.get('used_at'):
                                            reply_msg = "ç¶å®šç¢¼å·²ä½¿ç”¨ï¼Œè«‹å›ç¾¤çµ„é‡æ–°åŸ·è¡Œ !drive bindã€‚"
                                        elif code_record.get('requested_by_line_user_id') != user_id:
                                            reply_msg = "æ­¤ç¶å®šç¢¼ä¸æ˜¯ç”±ä½ å»ºç«‹ã€‚è«‹ç”±å»ºç«‹è€…å®Œæˆç¶å®šæˆ–é‡æ–°ç”¢ç”Ÿç¶å®šç¢¼ã€‚"
                                        else:
                                            client_id = os.getenv('GOOGLE_OAUTH_CLIENT_ID')
                                            redirect_base = os.getenv('OAUTH_REDIRECT_BASE')
                                            if not client_id or not redirect_base or not os.getenv('OAUTH_STATE_SIGNING_KEY'):
                                                reply_msg = "ä¼ºæœå™¨å°šæœªè¨­å®š Google OAuthï¼ˆç¼ºå°‘ç’°å¢ƒè®Šæ•¸ï¼‰ã€‚"
                                            else:
                                                redirect_uri = redirect_base.rstrip('/') + '/auth/google/callback'
                                                nonce = uuid.uuid4().hex
                                                exp = int(time.time()) + 10 * 60
                                                payload = {
                                                    'group_id': code_record.get('group_id'),
                                                    'line_user_id': user_id,
                                                    'bind_code': bind_code,
                                                    'nonce': nonce,
                                                    'exp': exp,
                                                }
                                                state = drive_export.sign_state(payload)

                                                code_record['oauth_nonce'] = nonce
                                                fdb.put('drive_bind_codes', bind_code, code_record)

                                                oauth_url = drive_export.build_google_oauth_url(
                                                    client_id=client_id,
                                                    redirect_uri=redirect_uri,
                                                    state=state,
                                                )
                                                reply_msg = f"è«‹é»é¸ä»¥ä¸‹é€£çµæˆæ¬Š Google Driveï¼š\n{oauth_url}"

                    elif text.lower() in ['!æ¸…ç©º', 'ï¼æ¸…ç©º', '!clean']:
                        try:
                            fdb.delete(user_chat_path, 'messages')
                            reply_msg = '------å°è©±æ­·å²ç´€éŒ„å·²ç¶“æ¸…ç©º------'
                            # æ¸…ç©ºå¾Œé‡ç½® messages
                            messages = []
                        except Exception as e:
                            logging.error(f"Failed to clear Firebase data: {e}")
                            reply_msg = 'æ¸…ç©ºå°è©±è¨˜éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦'

                    elif text.lower() in ['!æ‘˜è¦', 'ï¼æ‘˜è¦', '!ç¸½çµ', 'ï¼ç¸½çµ', 'ï¼summary']:
                        if len(messages) > 1:  # ç¢ºä¿æœ‰å°è©±å…§å®¹å¯ä»¥æ‘˜è¦
                            try:
                                model = genai.GenerativeModel(gemini_llm_model)
                                # æº–å‚™çµ¦ Gemini çš„è¨Šæ¯æ ¼å¼ï¼ˆç§»é™¤ timestamp æ¬„ä½ï¼‰
                                gemini_messages = []
                                for msg in messages:
                                    gemini_msg = {
                                        'role': msg['role'],
                                        'parts': msg['parts']
                                    }
                                    gemini_messages.append(gemini_msg)
                                
                                response = model.generate_content(
                                    f'Summary the following message in Traditional Chinese by less 5 list points. \n{gemini_messages}')
                                reply_msg = response.text
                                # è¨˜éŒ„æ‘˜è¦å›æ‡‰
                                messages.append({'role': 'model', 'parts': [reply_msg], 'timestamp': str(event.timestamp)})
                            except Exception as e:
                                logging.error(f"Error generating summary: {e}")
                                reply_msg = "æŠ±æ­‰ï¼Œç”¢ç”Ÿæ‘˜è¦æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
                        else:
                            reply_msg = 'ç›®å‰æ²’æœ‰è¶³å¤ çš„å°è©±ç´€éŒ„å¯ä»¥æ‘˜è¦'
                            messages.append({'role': 'model', 'parts': [reply_msg], 'timestamp': str(event.timestamp)})
                    
                    elif text.lower() in ['!help', '!å¹«åŠ©', 'ï¼help', 'ï¼å¹«åŠ©']:
                        reply_msg = """ğŸ¤– ç¾¤çµ„æ‘˜è¦ç‹ ä½¿ç”¨èªªæ˜

**ç¾¤çµ„åŠŸèƒ½ï¼š**
â€¢ @ æ©Ÿå™¨äºº + å•é¡Œï¼šé€²å…¥ AI å•ç­”æ¨¡å¼
  ä¾‹ï¼š@Bot ä»€éº¼æ˜¯æ¢¯åº¦ä¸‹é™ï¼Ÿ

â€¢ !æ‘˜è¦ æˆ– ï¼æ‘˜è¦ï¼šç”¢ç”Ÿå°è©±æ‘˜è¦
â€¢ !æ¸…ç©º æˆ– ï¼æ¸…ç©ºï¼šæ¸…ç©ºå°è©±è¨˜éŒ„
â€¢ !drive bindï¼šå•Ÿç”¨æ­¤ç¾¤çµ„ Google Drive è½‰å­˜ï¼ˆowner åˆ¶ï¼‰
  å…¶ä»–ï¼š!drive status / !drive off
â€¢ !ç•«åœ– [æè¿°] æˆ– ï¼ç•«åœ– [æè¿°]ï¼šç”Ÿæˆåœ–ç‰‡
  ä¾‹ï¼š!ç•«åœ– å¯æ„›çš„è²“å’ªåœ¨èŠ±åœ’è£¡ç©è€
  æç¤ºï¼šä½¿ç”¨å…·é«”ã€è©³ç´°çš„æè¿°æ•ˆæœæ›´å¥½
â€¢ !help æˆ– !å¹«åŠ©ï¼šé¡¯ç¤ºæ­¤èªªæ˜

**ç§äººåŠŸèƒ½ï¼š**
â€¢ ç›´æ¥å‚³é€è¨Šæ¯å³å¯èˆ‡ AI å°è©±
â€¢ æ”¯æ´æ‰€æœ‰ç¾¤çµ„æŒ‡ä»¤

**æ³¨æ„äº‹é …ï¼š**
â€¢ ç¾¤çµ„ä¸­åªæœ‰ @ æåŠæˆ–ç‰¹æ®ŠæŒ‡ä»¤æ‰æœƒå›æ‡‰
â€¢ AI å•ç­”ç‚ºä¸€æ¬¡æ€§å›ç­”ï¼Œä¸æœƒè¨˜éŒ„åˆ°å°è©±æ­·å²
â€¢ æ‰€æœ‰è¨Šæ¯éƒ½æœƒè¢«è¨˜éŒ„ä»¥ä¾›æ‘˜è¦åŠŸèƒ½ä½¿ç”¨
â€¢ åœ–ç‰‡ç”Ÿæˆéœ€è¦ Google Cloud Storage è¨­å®š"""
                        # å¹«åŠ©è¨Šæ¯ä¸è¨˜éŒ„åˆ°å°è©±æ­·å²
                        
                    elif any(cmd in text.lower() for cmd in ['!ç•«åœ–', 'ï¼ç•«åœ–', '!ç”Ÿæˆåœ–ç‰‡', 'ï¼ç”Ÿæˆåœ–ç‰‡', '!image', '!draw']):
                        # åœ–ç‰‡ç”ŸæˆåŠŸèƒ½
                        logging.info(f"Image generation command detected: {text}")
                        
                        if not bucket:
                            logging.error("Image generation requested but GCS not configured")
                            reply_msg = "æŠ±æ­‰ï¼Œåœ–ç‰‡ç”ŸæˆåŠŸèƒ½ç›®å‰ç„¡æ³•ä½¿ç”¨ï¼Œè«‹è¯ç¹«ç®¡ç†å“¡è¨­å®š Google Cloud Storageã€‚"
                        else:
                            # æå–åœ–ç‰‡æè¿°
                            prompt = text
                            for cmd in ['!ç•«åœ–', 'ï¼ç•«åœ–', '!ç”Ÿæˆåœ–ç‰‡', 'ï¼ç”Ÿæˆåœ–ç‰‡', '!image', '!draw']:
                                if cmd in text.lower():
                                    prompt = text.lower().replace(cmd, '').strip()
                                    logging.info(f"Extracted prompt using command '{cmd}': '{prompt}'")
                                    break
                            
                            if not prompt:
                                logging.warning("No prompt provided for image generation")
                                reply_msg = "è«‹æä¾›åœ–ç‰‡æè¿°ï¼Œä¾‹å¦‚ï¼š!ç•«åœ– å¯æ„›çš„è²“å’ªåœ¨èŠ±åœ’è£¡ç©è€"
                            else:
                                logging.info(f"Starting image generation process with prompt: '{prompt}'")
                                
                                # ä¸å…ˆç™¼é€"ç”Ÿæˆä¸­"è¨Šæ¯ï¼Œç›´æ¥ç”Ÿæˆåœ–ç‰‡å¾Œä¸€æ¬¡å›è¦†
                                logging.info("Calling generate_image_with_gemini...")
                                success, result = await generate_image_with_gemini(prompt)
                                logging.info(f"Image generation result - success: {success}, result: {result}")
                                
                                if success:
                                    logging.info("Image generation successful, sending reply with image")
                                    # ä½¿ç”¨ reply_message ä¸€æ¬¡ç™¼é€æ–‡å­—å’Œåœ–ç‰‡ï¼ˆé¿å… push_message é¡åº¦å•é¡Œï¼‰
                                    image_message = ImageMessage(
                                        original_content_url=result,
                                        preview_image_url=result
                                    )
                                    success_text = create_flex_message(f"ğŸ¨ åœ–ç‰‡ç”Ÿæˆå®Œæˆï¼š{prompt}", title="åœ–ç‰‡ç”Ÿæˆ", header_text="AI ç•«å®¶")
                                    
                                    await line_bot_api.reply_message(
                                        ReplyMessageRequest(
                                            reply_token=event.reply_token,
                                            messages=[success_text, image_message]
                                        )
                                    )
                                    logging.info("Image and text sent successfully via reply_message")
                                    reply_msg = ""  # å·²ç¶“å›è¦†äº†
                                else:
                                    logging.error(f"Image generation failed: {result}")
                                    # ä½¿ç”¨ reply_message ç™¼é€éŒ¯èª¤è¨Šæ¯
                                    reply_msg = f"âŒ åœ–ç‰‡ç”Ÿæˆå¤±æ•—ï¼š{result}"
                        
                        # åœ–ç‰‡ç”ŸæˆæŒ‡ä»¤ä¸è¨˜éŒ„åˆ°å°è©±æ­·å²
                        messages.pop()  # ç§»é™¤å‰›æ‰åŠ å…¥çš„ç”¨æˆ¶è¨Šæ¯
                        logging.info("Removed image generation command from conversation history")
                        
                    elif is_ai_question:
                        # AI å•ç­”æ¨¡å¼ï¼šä¸€æ¬¡æ€§å›ç­”ï¼Œä¸è¨˜éŒ„åˆ°å°è©±æ­·å²ï¼ˆç¾¤çµ„ä¸­çš„ @ æåŠï¼‰
                        try:
                            model = genai.GenerativeModel(gemini_llm_model)
                            # ç§»é™¤ @ æåŠéƒ¨åˆ†ï¼Œåªä¿ç•™å•é¡Œ
                            clean_question = text
                            if hasattr(event.message, 'mention') and event.message.mention:
                                # å¦‚æœæœ‰ mention è³‡è¨Šï¼Œç§»é™¤è¢«æåŠçš„éƒ¨åˆ†
                                mention = event.message.mention
                                for mentioned_user in mention.mentionees:
                                    if mentioned_user.user_id:
                                        # ç°¡å–®çš„æ–‡å­—æ¸…ç†ï¼Œç§»é™¤å¯èƒ½çš„ @ ç¬¦è™Ÿ
                                        clean_question = text.replace('@', '').strip()
                            
                            response = model.generate_content(f"è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ä»¥ä¸‹å•é¡Œï¼š{clean_question}")
                            reply_msg = response.text
                            # AI å•ç­”ä¸è¨˜éŒ„åˆ°å°è©±æ­·å²ï¼Œæ‰€ä»¥ç§»é™¤å‰›åŠ å…¥çš„è¨Šæ¯
                            messages.pop()  # ç§»é™¤å‰›æ‰åŠ å…¥çš„ç”¨æˆ¶è¨Šæ¯
                        except Exception as e:
                            logging.error(f"Error in AI question mode: {e}")
                            reply_msg = "æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
                            messages.pop()  # ç§»é™¤å‰›æ‰åŠ å…¥çš„ç”¨æˆ¶è¨Šæ¯
                            
                    else:
                        # ä¸€èˆ¬å°è©±ï¼ˆç§äººå°è©±æˆ–ç¾¤çµ„ä¸­çš„å…¶ä»–æƒ…æ³ï¼‰
                        try:
                            model = genai.GenerativeModel(gemini_llm_model)
                            # æº–å‚™çµ¦ Gemini çš„è¨Šæ¯æ ¼å¼ï¼ˆç§»é™¤ timestamp æ¬„ä½ï¼‰
                            gemini_messages = []
                            for msg in messages:
                                gemini_msg = {
                                    'role': msg['role'],
                                    'parts': msg['parts']
                                }
                                gemini_messages.append(gemini_msg)
                            
                            response = model.generate_content(gemini_messages)
                            reply_msg = response.text
                            messages.append({'role': 'model', 'parts': [reply_msg], 'timestamp': str(event.timestamp)})
                            logging.info(f"Generated AI response for general conversation: {reply_msg[:50]}...")
                        except Exception as e:
                            logging.error(f"Error in general conversation: {e}")
                            reply_msg = "æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
                
                # æ›´æ–° Firebase ä¸­çš„å°è©±ç´€éŒ„
                # AI å•ç­”æ¨¡å¼ã€å¹«åŠ©è¨Šæ¯å’Œåœ–ç‰‡ç”ŸæˆæŒ‡ä»¤ä¸è¨˜éŒ„åˆ°å°è©±æ­·å²
                should_save_to_firebase = not is_ai_question and not (
                    text.lower() in ['!help', '!å¹«åŠ©', 'ï¼help', 'ï¼å¹«åŠ©'] or
                    any(cmd in text.lower() for cmd in ['!ç•«åœ–', 'ï¼ç•«åœ–', '!ç”Ÿæˆåœ–ç‰‡', 'ï¼ç”Ÿæˆåœ–ç‰‡', '!image', '!draw']) or
                    is_drive_command
                )
                
                if should_save_to_firebase:
                    try:
                        fdb.put(user_chat_path, 'messages', messages)
                        logging.info(f"Saved message to Firebase: {user_chat_path}")
                    except Exception as e:
                        logging.error(f"Failed to save to Firebase: {e}")
                else:
                    logging.info(f"Skipped saving to Firebase (special command): {text[:50]}...")

                # ç™¼é€å›æ‡‰ï¼ˆåªæœ‰åœ¨éœ€è¦å›æ‡‰ä¸”æœ‰è¨Šæ¯å…§å®¹æ™‚ï¼‰
                if should_reply and reply_msg:
                    await line_bot_api.reply_message(
                        ReplyMessageRequest(
                            reply_token=event.reply_token,
                            messages=[create_flex_message(reply_msg)]
                        ))
    
    finally:
        # é—œé–‰ async client
        await async_api_client.close()

    return 'OK'

if __name__ == "__main__":
    port = int(os.environ.get('PORT', default=8080))
    debug = True if os.environ.get(
        'API_ENV', default='develop') == 'develop' else False
    logging.info('Application will start...')
    uvicorn.run("main:app", host="0.0.0.0", port=port, reload=debug)
