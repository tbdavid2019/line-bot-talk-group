import logging
import os
import sys
if os.getenv('API_ENV') != 'production':
    from dotenv import load_dotenv

    load_dotenv()


from fastapi import FastAPI, HTTPException, Request
from linebot.v3.webhook import WebhookParser
from linebot.v3.messaging import (
    AsyncApiClient,
    AsyncMessagingApi,
    Configuration,
    ReplyMessageRequest,
    TextMessage)
from linebot.v3.exceptions import (
    InvalidSignatureError
)
from linebot.v3.webhooks import (
    MessageEvent,
    TextMessageContent,
)
import google.generativeai as genai
import uvicorn
from firebase import firebase

logging.basicConfig(level=os.getenv('LOG', 'WARNING'))
logger = logging.getLogger(__file__)

app = FastAPI()

channel_secret = os.getenv('LINE_CHANNEL_SECRET', None)
channel_access_token = os.getenv('LINE_CHANNEL_ACCESS_TOKEN', None)
if channel_secret is None:
    print('Specify LINE_CHANNEL_SECRET as environment variable.')
    sys.exit(1)
if channel_access_token is None:
    print('Specify LINE_CHANNEL_ACCESS_TOKEN as environment variable.')
    sys.exit(1)

configuration = Configuration(
    access_token=channel_access_token
)

parser = WebhookParser(channel_secret)


firebase_url = os.getenv('FIREBASE_URL')
gemini_key = os.getenv('GEMINI_API_KEY')
gemini_model = os.getenv('GEMINI_MODEL', 'gemini-2.5-flash')
bot_line_id = os.getenv('LINE_BOT_ID', '377mwhqu')  # Bot çš„ LINE ID


# Initialize the Gemini Pro API
genai.configure(api_key=gemini_key)


def is_bot_mentioned(event, bot_id=None):
    """
    æª¢æŸ¥æ˜¯å¦ Bot è¢«æåŠ
    
    Args:
        event: LINE webhook event
        bot_id: Bot çš„ LINE IDï¼ˆå¯é¸ï¼‰
    
    Returns:
        bool: True å¦‚æœ Bot è¢«æåŠï¼ŒFalse å¦å‰‡
    """
    if not isinstance(event.message, TextMessageContent):
        return False
    
    text = event.message.text
    mention = getattr(event.message, 'mention', None)
    
    # æ–¹æ³•1: æª¢æŸ¥ mention ç‰©ä»¶ä¸­æ˜¯å¦åŒ…å«ç‰¹å®šçš„ç”¨æˆ¶ID
    if mention and hasattr(mention, 'mentionees'):
        # æ³¨æ„ï¼šé€™éœ€è¦çŸ¥é“ Bot çš„å¯¦éš› user_idï¼Œé€šå¸¸æ ¼å¼ç‚º Ué–‹é ­
        # ä½†æˆ‘å€‘å¯èƒ½ç„¡æ³•ç›´æ¥ç²å–åˆ° Bot è‡ªå·±çš„ user_id
        pass
    
    # æ–¹æ³•2: æª¢æŸ¥æ–‡å­—ä¸­æ˜¯å¦åŒ…å« Bot çš„å®˜æ–¹ ID
    if bot_id:
        # æª¢æŸ¥æ˜¯å¦åŒ…å« @bot_id æ ¼å¼ï¼ˆç¢ºä¿ @ å‰é¢æ²’æœ‰å…¶ä»–å­—ç¬¦ï¼‰
        import re
        bot_patterns = [
            rf'(?<![a-zA-Z0-9])@{re.escape(bot_id)}(?![a-zA-Z0-9])',
            rf'(?<![a-zA-Z0-9])ï¼ {re.escape(bot_id)}(?![a-zA-Z0-9])',
            rf'(?<![a-zA-Z0-9])@{re.escape(bot_id.lower())}(?![a-zA-Z0-9])',
            rf'(?<![a-zA-Z0-9])ï¼ {re.escape(bot_id.lower())}(?![a-zA-Z0-9])'
        ]
        
        for pattern in bot_patterns:
            if re.search(pattern, text):
                logging.info(f"Bot mentioned with pattern: {pattern}")
                return True
    
    # æ–¹æ³•3: æª¢æŸ¥æ˜¯å¦æœ‰ mention ä¸”æ–‡å­—åŒ…å«é—œéµè©
    if mention:
        # æª¢æŸ¥å¸¸è¦‹çš„ Bot å‘¼å«æ–¹å¼
        bot_keywords = ['bot', 'Bot', 'BOT', 'æ©Ÿå™¨äºº', 'æ‘˜è¦ç‹']
        if any(keyword in text for keyword in bot_keywords):
            logging.info(f"Bot mentioned with keyword in text: {text}")
            return True
    
    return False


@app.get("/health")
async def health():
    return 'ok'

@app.get("/")
async def root():
    return {"message": "LINE Bot is running", "status": "ok"}


@app.post("/webhooks/line")
async def handle_callback(request: Request):
    signature = request.headers['X-Line-Signature']

    # get request body as text
    body = await request.body()
    body = body.decode()

    try:
        events = parser.parse(body, signature)
    except InvalidSignatureError:
        raise HTTPException(status_code=400, detail="Invalid signature")

    # å‰µå»º async client åœ¨ async å‡½æ•¸å…§
    async_api_client = AsyncApiClient(configuration)
    line_bot_api = AsyncMessagingApi(async_api_client)
    
    try:
        for event in events:
            logging.info(event)
            if not isinstance(event, MessageEvent):
                continue
            if not isinstance(event.message, TextMessageContent):
                continue
            text = event.message.text
            user_id = event.source.user_id

            msg_type = event.message.type
            fdb = firebase.FirebaseApplication(firebase_url, None)
            
            # è¨­å®š Firebase è·¯å¾‘
            if event.source.type == 'group':
                user_chat_path = f'groups/{event.source.group_id}'
            else:
                user_chat_path = f'users/{user_id}'
            
            # æ±ºå®šæ˜¯å¦è¦å›æ‡‰
            should_reply = False
            is_ai_question = False  # æ˜¯å¦ç‚º AI å•ç­”æ¨¡å¼
            special_commands = ['!æ¸…ç©º', '!clean',  '!æ‘˜è¦','!ç¸½çµ','!summary', 'ï¼æ¸…ç©º', 'ï¼æ‘˜è¦', '!help', '!å¹«åŠ©', 'ï¼help', 'ï¼å¹«åŠ©']
            
            if event.source.type == 'group':
                # æª¢æŸ¥æ˜¯å¦çœŸçš„æåŠäº† Bot
                bot_mentioned = is_bot_mentioned(event, bot_line_id)
                
                # æª¢æŸ¥æ˜¯å¦åŒ…å«ç‰¹æ®ŠæŒ‡ä»¤
                has_special_command = any(cmd in text.lower() for cmd in special_commands)
                
                if bot_mentioned and not has_special_command:
                    # Bot è¢«æåŠä½†ä¸æ˜¯ç‰¹æ®ŠæŒ‡ä»¤ = AI å•ç­”æ¨¡å¼
                    should_reply = True
                    is_ai_question = True
                    logging.info(f"Bot mentioned - AI question mode: '{text}'")
                elif has_special_command:
                    # ç‰¹æ®ŠæŒ‡ä»¤
                    should_reply = True
                    logging.info(f"Group message with special command: '{text}'")
                else:
                    logging.info(f"Recording group message (no reply): '{text}'")
            else:
                # ç§äººå°è©±ï¼šæ‰€æœ‰è¨Šæ¯éƒ½å›æ‡‰
                should_reply = True
                # æª¢æŸ¥æ˜¯å¦ç‚ºç‰¹æ®ŠæŒ‡ä»¤
                has_special_command = any(cmd in text.lower() for cmd in special_commands)
                if not has_special_command:
                    # ä¸€èˆ¬å°è©±æ¨¡å¼
                    logging.info(f"Private conversation mode: '{text}'")
                else:
                    logging.info(f"Private message with special command: '{text}'")
            
            # ç²å–ç¾æœ‰å°è©±è¨˜éŒ„
            try:
                chatgpt = fdb.get(user_chat_path, 'messages')
                if chatgpt is None:
                    messages = []
                else:
                    messages = chatgpt if isinstance(chatgpt, list) else []
            except Exception as e:
                logging.warning(f"Failed to get messages from Firebase: {e}")
                messages = []

            if msg_type == 'text':
                # æ‰€æœ‰è¨Šæ¯éƒ½è¨˜éŒ„åˆ° Firebase
                messages.append({'role': 'user', 'parts': [text], 'timestamp': str(event.timestamp)})
                
                reply_msg = ""
                
                # åªæœ‰åœ¨éœ€è¦å›æ‡‰æ™‚æ‰è™•ç†
                if should_reply:
                    if text.lower() in ['!æ¸…ç©º', 'ï¼æ¸…ç©º', '!clean']:
                        try:
                            fdb.delete(user_chat_path, 'messages')
                            reply_msg = '------å°è©±æ­·å²ç´€éŒ„å·²ç¶“æ¸…ç©º------'
                            # æ¸…ç©ºå¾Œé‡ç½® messages
                            messages = []
                        except Exception as e:
                            logging.error(f"Failed to clear Firebase data: {e}")
                            reply_msg = 'æ¸…ç©ºå°è©±è¨˜éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦'

                    elif text.lower() in ['!æ‘˜è¦', 'ï¼æ‘˜è¦', '!ç¸½çµ', 'ï¼ç¸½çµ', 'ï¼summary']:
                        if len(messages) > 1:  # ç¢ºä¿æœ‰å°è©±å…§å®¹å¯ä»¥æ‘˜è¦
                            try:
                                model = genai.GenerativeModel(gemini_model)
                                # æº–å‚™çµ¦ Gemini çš„è¨Šæ¯æ ¼å¼ï¼ˆç§»é™¤ timestamp æ¬„ä½ï¼‰
                                gemini_messages = []
                                for msg in messages:
                                    gemini_msg = {
                                        'role': msg['role'],
                                        'parts': msg['parts']
                                    }
                                    gemini_messages.append(gemini_msg)
                                
                                response = model.generate_content(
                                    f'Summary the following message in Traditional Chinese by less 5 list points. \n{gemini_messages}')
                                reply_msg = response.text
                                # è¨˜éŒ„æ‘˜è¦å›æ‡‰
                                messages.append({'role': 'model', 'parts': [reply_msg], 'timestamp': str(event.timestamp)})
                            except Exception as e:
                                logging.error(f"Error generating summary: {e}")
                                reply_msg = "æŠ±æ­‰ï¼Œç”¢ç”Ÿæ‘˜è¦æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
                        else:
                            reply_msg = 'ç›®å‰æ²’æœ‰è¶³å¤ çš„å°è©±ç´€éŒ„å¯ä»¥æ‘˜è¦'
                            messages.append({'role': 'model', 'parts': [reply_msg], 'timestamp': str(event.timestamp)})
                    
                    elif text.lower() in ['!help', '!å¹«åŠ©', 'ï¼help', 'ï¼å¹«åŠ©']:
                        reply_msg = """ğŸ¤– ç¾¤çµ„æ‘˜è¦ç‹ ä½¿ç”¨èªªæ˜

**ç¾¤çµ„åŠŸèƒ½ï¼š**
â€¢ @ æ©Ÿå™¨äºº + å•é¡Œï¼šé€²å…¥ AI å•ç­”æ¨¡å¼
  ä¾‹ï¼š@Bot ä»€éº¼æ˜¯æ¢¯åº¦ä¸‹é™ï¼Ÿ

â€¢ !æ‘˜è¦ æˆ– ï¼æ‘˜è¦ï¼šç”¢ç”Ÿå°è©±æ‘˜è¦
â€¢ !æ¸…ç©º æˆ– ï¼æ¸…ç©ºï¼šæ¸…ç©ºå°è©±è¨˜éŒ„
â€¢ !help æˆ– !å¹«åŠ©ï¼šé¡¯ç¤ºæ­¤èªªæ˜

**ç§äººåŠŸèƒ½ï¼š**
â€¢ ç›´æ¥å‚³é€è¨Šæ¯å³å¯èˆ‡ AI å°è©±
â€¢ æ”¯æ´æ‰€æœ‰ç¾¤çµ„æŒ‡ä»¤

**æ³¨æ„äº‹é …ï¼š**
â€¢ ç¾¤çµ„ä¸­åªæœ‰ @ æåŠæˆ–ç‰¹æ®ŠæŒ‡ä»¤æ‰æœƒå›æ‡‰
â€¢ AI å•ç­”ç‚ºä¸€æ¬¡æ€§å›ç­”ï¼Œä¸æœƒè¨˜éŒ„åˆ°å°è©±æ­·å²
â€¢ æ‰€æœ‰è¨Šæ¯éƒ½æœƒè¢«è¨˜éŒ„ä»¥ä¾›æ‘˜è¦åŠŸèƒ½ä½¿ç”¨"""
                        # å¹«åŠ©è¨Šæ¯ä¸è¨˜éŒ„åˆ°å°è©±æ­·å²
                        
                    elif is_ai_question:
                        # AI å•ç­”æ¨¡å¼ï¼šä¸€æ¬¡æ€§å›ç­”ï¼Œä¸è¨˜éŒ„åˆ°å°è©±æ­·å²ï¼ˆç¾¤çµ„ä¸­çš„ @ æåŠï¼‰
                        try:
                            model = genai.GenerativeModel(gemini_model)
                            # ç§»é™¤ @ æåŠéƒ¨åˆ†ï¼Œåªä¿ç•™å•é¡Œ
                            clean_question = text
                            if hasattr(event.message, 'mention') and event.message.mention:
                                # å¦‚æœæœ‰ mention è³‡è¨Šï¼Œç§»é™¤è¢«æåŠçš„éƒ¨åˆ†
                                mention = event.message.mention
                                for mentioned_user in mention.mentionees:
                                    if mentioned_user.user_id:
                                        # ç°¡å–®çš„æ–‡å­—æ¸…ç†ï¼Œç§»é™¤å¯èƒ½çš„ @ ç¬¦è™Ÿ
                                        clean_question = text.replace('@', '').strip()
                            
                            response = model.generate_content(f"è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ä»¥ä¸‹å•é¡Œï¼š{clean_question}")
                            reply_msg = response.text
                            # AI å•ç­”ä¸è¨˜éŒ„åˆ°å°è©±æ­·å²ï¼Œæ‰€ä»¥ç§»é™¤å‰›åŠ å…¥çš„è¨Šæ¯
                            messages.pop()  # ç§»é™¤å‰›æ‰åŠ å…¥çš„ç”¨æˆ¶è¨Šæ¯
                        except Exception as e:
                            logging.error(f"Error in AI question mode: {e}")
                            reply_msg = "æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
                            messages.pop()  # ç§»é™¤å‰›æ‰åŠ å…¥çš„ç”¨æˆ¶è¨Šæ¯
                            
                    else:
                        # ä¸€èˆ¬å°è©±ï¼ˆç§äººå°è©±æˆ–ç¾¤çµ„ä¸­çš„å…¶ä»–æƒ…æ³ï¼‰
                        try:
                            model = genai.GenerativeModel(gemini_model)
                            # æº–å‚™çµ¦ Gemini çš„è¨Šæ¯æ ¼å¼ï¼ˆç§»é™¤ timestamp æ¬„ä½ï¼‰
                            gemini_messages = []
                            for msg in messages:
                                gemini_msg = {
                                    'role': msg['role'],
                                    'parts': msg['parts']
                                }
                                gemini_messages.append(gemini_msg)
                            
                            response = model.generate_content(gemini_messages)
                            reply_msg = response.text
                            messages.append({'role': 'model', 'parts': [reply_msg], 'timestamp': str(event.timestamp)})
                            logging.info(f"Generated AI response for general conversation: {reply_msg[:50]}...")
                        except Exception as e:
                            logging.error(f"Error in general conversation: {e}")
                            reply_msg = "æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
                
                # æ›´æ–° Firebase ä¸­çš„å°è©±ç´€éŒ„
                # AI å•ç­”æ¨¡å¼å’Œå¹«åŠ©è¨Šæ¯ä¸è¨˜éŒ„åˆ°å°è©±æ­·å²
                if not is_ai_question and not (text.lower() in ['!help', '!å¹«åŠ©', 'ï¼help', 'ï¼å¹«åŠ©']):
                    try:
                        fdb.put(user_chat_path, 'messages', messages)
                        logging.info(f"Saved message to Firebase: {user_chat_path}")
                    except Exception as e:
                        logging.error(f"Failed to save to Firebase: {e}")
                else:
                    logging.info(f"Skipped saving to Firebase (AI question or help): {text[:50]}...")

                # ç™¼é€å›æ‡‰ï¼ˆåªæœ‰åœ¨éœ€è¦å›æ‡‰æ™‚ï¼‰
                if should_reply and reply_msg:
                    await line_bot_api.reply_message(
                        ReplyMessageRequest(
                            reply_token=event.reply_token,
                            messages=[TextMessage(text=reply_msg)]
                        ))
    
    finally:
        # é—œé–‰ async client
        await async_api_client.close()

    return 'OK'

if __name__ == "__main__":
    port = int(os.environ.get('PORT', default=8080))
    debug = True if os.environ.get(
        'API_ENV', default='develop') == 'develop' else False
    logging.info('Application will start...')
    uvicorn.run("main:app", host="0.0.0.0", port=port, reload=debug)
